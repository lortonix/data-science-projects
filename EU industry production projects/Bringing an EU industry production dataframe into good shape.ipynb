{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, I read in a subset of the EU industry production dataset from a local PostgreSQL database into a pandas dataframe, using SQLalchemy. The SQL query selects the manufacturing (category \"C\") production data index for all countries, adjusted for calendar and season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36 entries, 0 to 35\n",
      "Columns: 781 entries, indic_bt to 1953M01\n",
      "dtypes: object(781)\n",
      "memory usage: 219.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# Specify the SQL query for selecting the desired subset\n",
    "query = 'SELECT * FROM industry_production WHERE nace_r2=\\'C\\' AND s_adj=\\'SCA\\' AND unit=\\'I10\\''\n",
    "\n",
    "# Establish connection to PostgreSQL database\n",
    "engine = sqlalchemy.create_engine(\"postgresql://postgres:xfkLVeMj@localhost/production\")\n",
    "\n",
    "# Execute SQL query and store result as dataframe\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the dataframe a bit closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  indic_bt nace_r2 s_adj unit geo\\time 2017M08  2017M07  2017M06  2017M05   \\\n",
      "0     PROD       C   SCA  I10       UK       :    104.5    103.9    103.9    \n",
      "1     PROD       C   SCA  I10       TR       :   135.2 p  132.4 p  132.8 p   \n",
      "2     PROD       C   SCA  I10       SK       :   145.9 p   154.8    155.6    \n",
      "3     PROD       C   SCA  I10       SI       :   124.9 p  124.6 p  125.1 p   \n",
      "4     PROD       C   SCA  I10       SE       :    101.5    102.2    101.2    \n",
      "\n",
      "  2017M04    ...   1953M10  1953M09  1953M08  1953M07  1953M06  1953M05   \\\n",
      "0   104.0    ...         :        :        :        :        :        :    \n",
      "1  135.6 p   ...         :        :        :        :        :        :    \n",
      "2   148.0    ...         :        :        :        :        :        :    \n",
      "3  123.2 p   ...         :        :        :        :        :        :    \n",
      "4    98.1    ...         :        :        :        :        :        :    \n",
      "\n",
      "  1953M04  1953M03  1953M02  1953M01  \n",
      "0       :        :        :        :  \n",
      "1       :        :        :        :  \n",
      "2       :        :        :        :  \n",
      "3       :        :        :        :  \n",
      "4       :        :        :        :  \n",
      "\n",
      "[5 rows x 781 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first four columns do not offer any additional information because there is only a single value in each column, based on the \"WHERE\" filter of the query. Let us get rid of them with the \"drop()\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  geo\\time 2017M08  2017M07  2017M06  2017M05  2017M04  2017M03  2017M02   \\\n",
      "0       UK       :    104.5    103.9    103.9    104.0    104.0    104.6    \n",
      "1       TR       :   135.2 p  132.4 p  132.8 p  135.6 p  132.2 p  130.3 p   \n",
      "2       SK       :   145.9 p   154.8    155.6    148.0    160.3    153.0    \n",
      "3       SI       :   124.9 p  124.6 p  125.1 p  123.2 p  124.1 p  122.3 p   \n",
      "4       SE       :    101.5    102.2    101.2     98.1    100.6    100.6    \n",
      "\n",
      "  2017M01  2016M12    ...   1953M10  1953M09  1953M08  1953M07  1953M06   \\\n",
      "0   105.0    106.2    ...         :        :        :        :        :    \n",
      "1  131.3 p  129.4 p   ...         :        :        :        :        :    \n",
      "2   153.4    154.1    ...         :        :        :        :        :    \n",
      "3  117.6 p  121.8 p   ...         :        :        :        :        :    \n",
      "4   100.1     96.6    ...         :        :        :        :        :    \n",
      "\n",
      "  1953M05  1953M04  1953M03  1953M02  1953M01  \n",
      "0       :        :        :        :        :  \n",
      "1       :        :        :        :        :  \n",
      "2       :        :        :        :        :  \n",
      "3       :        :        :        :        :  \n",
      "4       :        :        :        :        :  \n",
      "\n",
      "[5 rows x 777 columns]\n"
     ]
    }
   ],
   "source": [
    "df.drop(['indic_bt','nace_r2','s_adj','unit'], axis=1, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter \"axis=1\" tells Pandas that the things to be dropped are columns (instead of rows), and \"inplace=True\" applies the deletion to \"df\" itself (instead of a copy).\n",
    "\n",
    "As a next step, I change the messed up name of the \"geo\\time\" column to something more meaningful. The \"rename()\" method takes a dictionary with entries of the form \"'old_name':'new_name'\" for the column parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'geo\\\\time':'country_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country_code 2017M08  2017M07  2017M06  2017M05  2017M04  2017M03  2017M02   \\\n",
      "0           UK       :    104.5    103.9    103.9    104.0    104.0    104.6    \n",
      "1           TR       :   135.2 p  132.4 p  132.8 p  135.6 p  132.2 p  130.3 p   \n",
      "2           SK       :   145.9 p   154.8    155.6    148.0    160.3    153.0    \n",
      "3           SI       :   124.9 p  124.6 p  125.1 p  123.2 p  124.1 p  122.3 p   \n",
      "4           SE       :    101.5    102.2    101.2     98.1    100.6    100.6    \n",
      "\n",
      "  2017M01  2016M12    ...   1953M10  1953M09  1953M08  1953M07  1953M06   \\\n",
      "0   105.0    106.2    ...         :        :        :        :        :    \n",
      "1  131.3 p  129.4 p   ...         :        :        :        :        :    \n",
      "2   153.4    154.1    ...         :        :        :        :        :    \n",
      "3  117.6 p  121.8 p   ...         :        :        :        :        :    \n",
      "4   100.1     96.6    ...         :        :        :        :        :    \n",
      "\n",
      "  1953M05  1953M04  1953M03  1953M02  1953M01  \n",
      "0       :        :        :        :        :  \n",
      "1       :        :        :        :        :  \n",
      "2       :        :        :        :        :  \n",
      "3       :        :        :        :        :  \n",
      "4       :        :        :        :        :  \n",
      "\n",
      "[5 rows x 777 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this dataframe structure is quite convenient to read as a human (ignoring its sheer size for a moment...), for data analysis purposes it is not optimal: The time series is spread over many columns and the time stamps are strings in a non-standard format.\n",
    "\n",
    "To tidy up the dataframe now, I first need to know what the (i) variables, (ii) observations, and (iii) types of observational units are.\n",
    "\n",
    "Point (iii) is simple: I only selected the production index from the PostgreSQL table. The variables are the country code, the time, and the production index. The observations are production index values for a given country and month.\n",
    "\n",
    "A tidy version of the dataframe would thus have three columns (time, country_code, production_index) and many rows. The columns are typically ordered like this: Fixed variables, i.e. variables that define the experimental setup, come first (time, country_code). Measured variables (production_index) come later.\n",
    "\n",
    "In the current structure of the dataframe, country_code is already a column, but time is not. Instead, the time values (months) are separate columns. I can store the column names in a time column using the pandas method \"melt()\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27936 entries, 0 to 27935\n",
      "Data columns (total 3 columns):\n",
      "country_code        27936 non-null object\n",
      "time                27936 non-null object\n",
      "production_index    27936 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 654.8+ KB\n",
      "  country_code      time production_index\n",
      "0           UK  2017M08                : \n",
      "1           TR  2017M08                : \n",
      "2           SK  2017M08                : \n",
      "3           SI  2017M08                : \n",
      "4           SE  2017M08                : \n"
     ]
    }
   ],
   "source": [
    "df_melted = pd.melt(df, id_vars=['country_code'], var_name='time', value_name='production_index')\n",
    "df_melted.info()\n",
    "print(df_melted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"melt()\" method takes all columns that are not listed in the \"id_vars\" argument and puts the column names in a \"variable\" column and the values in a \"value\" column. I have changed these standard column names to 'time' and 'production_index' using the \"var_name\" and \"value_name\" arguments.\n",
    "\n",
    "The current shape of the dataframe after applying the \"melt()\" method is already much closer to the desired tidy form. However, the \"time\" values are still strings (\"non-null object\" in the \"info()\" method output), so Python does not \"know\" about the dataset being a time series. This can be changed by transforming the \"time\" column into a DatetimeIndex. First, I convert the time column from string into Datetime format with the \"to_datetime()\" method. To help the parser understand the format, I replace the 'M' in the string with a dash before passing the column to the conversion method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27936 entries, 0 to 27935\n",
      "Data columns (total 3 columns):\n",
      "country_code        27936 non-null object\n",
      "time                27936 non-null datetime64[ns]\n",
      "production_index    27936 non-null object\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 654.8+ KB\n",
      "  country_code       time production_index\n",
      "0           UK 2017-08-01               : \n",
      "1           TR 2017-08-01               : \n",
      "2           SK 2017-08-01               : \n",
      "3           SI 2017-08-01               : \n",
      "4           SE 2017-08-01               : \n"
     ]
    }
   ],
   "source": [
    "df_melted['time'] = pd.to_datetime(df_melted['time'].str.replace('M','-'))\n",
    "df_melted.info()\n",
    "print(df_melted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can use the time column to obtain a DatetimeIndex, using the \"set_index()\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 27936 entries, 2017-08-01 to 1953-01-01\n",
      "Data columns (total 2 columns):\n",
      "country_code        27936 non-null object\n",
      "production_index    27936 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 654.8+ KB\n",
      "           country_code production_index\n",
      "time                                    \n",
      "2017-08-01           UK               : \n",
      "2017-08-01           TR               : \n",
      "2017-08-01           SK               : \n",
      "2017-08-01           SI               : \n",
      "2017-08-01           SE               : \n"
     ]
    }
   ],
   "source": [
    "df_tidy = df_melted.set_index('time')\n",
    "df_tidy.info()\n",
    "print(df_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better! There is, however, one more thing to consider: Not only \"time\", but also \"country_code\" is a fixed variable of the dataset. The dataset is thus two-dimensional. In pandas, this can be reflected by a multi-dimensional index, or short, \"MultiIndex\". It is simply constructed by providing a list of column names to the \"set_index()\" method instead of a single column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 27936 entries, (2017-08-01 00:00:00, UK) to (1953-01-01 00:00:00, AT)\n",
      "Data columns (total 1 columns):\n",
      "production_index    27936 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 306.5+ KB\n",
      "                        production_index\n",
      "time       country_code                 \n",
      "2017-08-01 UK                         : \n",
      "           TR                         : \n",
      "           SK                         : \n",
      "           SI                         : \n",
      "           SE                         : \n"
     ]
    }
   ],
   "source": [
    "df_tidy = df_melted.set_index(['time','country_code'])\n",
    "df_tidy.info()\n",
    "print(df_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure is a much more natural representation of the dataset for data analysis with pandas dataframes.\n",
    "\n",
    "As a last step, I sort the index (dates in chronological order, country codes in alphabetical order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 27936 entries, (1953-01-01 00:00:00, AT) to (2017-08-01 00:00:00, UK)\n",
      "Data columns (total 1 columns):\n",
      "production_index    27936 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 306.5+ KB\n",
      "                        production_index\n",
      "time       country_code                 \n",
      "1953-01-01 AT                          :\n",
      "           BA                          :\n",
      "           BE                          :\n",
      "           BG                          :\n",
      "           CY                          :\n"
     ]
    }
   ],
   "source": [
    "df_tidy.sort_index(inplace=True)\n",
    "df_tidy.info()\n",
    "print(df_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides bringing the dataframe in a neat order, this is also necessary to slice it (e.g., extract a certain date range) in future projects.\n",
    "\n",
    "For further projects, I save the dataframe as a serialized file on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tidy.to_pickle('EU_industry_production_dataframe.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
